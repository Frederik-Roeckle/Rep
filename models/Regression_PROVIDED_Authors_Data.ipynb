{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Frederik-Roeckle/Rep_ImpactProcessComplexity/blob/master/Regression_PROVIDED_Authors_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_p1uNdD3jqxb"
      },
      "outputs": [],
      "source": [
        "import pandas\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "import statsmodels.api as sm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "data = 'merged.csv'\n",
        "\n",
        "# Freddys google drive path\n",
        "data = '/content/drive/MyDrive/Colab Notebooks/Rep_ProcessMining/provided/merged.csv'\n",
        "\n",
        "data = pd.read_csv(data)"
      ],
      "metadata": {
        "id": "6N35tCIUkEzp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8db50ce-c8cd-431b-e449-204cd68a91de"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datas = data.copy()\n",
        "\n",
        "datas.info()"
      ],
      "metadata": {
        "id": "Jwy5lhdJkpeR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "952a4949-0727-4c49-aa0c-f1f1e64e471b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1474 entries, 0 to 1473\n",
            "Data columns (total 56 columns):\n",
            " #   Column                                                             Non-Null Count  Dtype  \n",
            "---  ------                                                             --------------  -----  \n",
            " 0   Date                                                               1474 non-null   object \n",
            " 1   Cases                                                              1474 non-null   int64  \n",
            " 2   Distinct activities                                                1474 non-null   object \n",
            " 3   Number of distinct activities                                      1474 non-null   int64  \n",
            " 4   Number of simple cycles in period                                  1474 non-null   int64  \n",
            " 5   Average number of simple cycles per trace                          1474 non-null   float64\n",
            " 6   Median number of simple cycles per trace                           1474 non-null   float64\n",
            " 7   Number of activity repetitions in period                           1474 non-null   int64  \n",
            " 8   Average number of activity repetitions per trace                   1474 non-null   float64\n",
            " 9   Median number of activity repetitions per trace                    1474 non-null   float64\n",
            " 10  Number of participants in period                                   1429 non-null   float64\n",
            " 11  Average number of participants per trace                           1429 non-null   float64\n",
            " 12  Median number of participants per trace                            1429 non-null   float64\n",
            " 13  Handover of work in period                                         1429 non-null   float64\n",
            " 14  Average handover of work per trace                                 1429 non-null   float64\n",
            " 15  Median handover of work per trace                                  1429 non-null   float64\n",
            " 16  Average handover of work from participant                          1429 non-null   float64\n",
            " 17  Median handover of work from participant                           1429 non-null   float64\n",
            " 18  Simple Variant Entropy                                             1474 non-null   float64\n",
            " 19  Simple Normalized Variant Entropy                                  1474 non-null   float64\n",
            " 20  Simple Sequence Entropy                                            1474 non-null   float64\n",
            " 21  Simple Normalized Sequence Entropy                                 1474 non-null   float64\n",
            " 22  Simple Sequence Entropy (linear forgetting)                        1474 non-null   float64\n",
            " 23  Simple Normalized Sequence Entropy (linear forgetting)             1474 non-null   float64\n",
            " 24  Simple Sequence Entropy (exponential forgetting, k1)               1474 non-null   float64\n",
            " 25  Simple Normalized Sequence Entropy (exponential forgetting, k1)    1474 non-null   float64\n",
            " 26  Enriched Variant Entropy                                           1474 non-null   float64\n",
            " 27  Enriched Normalized Variant Entropy                                1474 non-null   float64\n",
            " 28  Enriched Sequence Entropy                                          1474 non-null   float64\n",
            " 29  Enriched Normalized Sequence Entropy                               1474 non-null   float64\n",
            " 30  Enriched Sequence Entropy (linear forgetting)                      1474 non-null   float64\n",
            " 31  Enriched Normalized Sequence Entropy (linear forgetting)           1474 non-null   float64\n",
            " 32  Enriched Sequence Entropy (exponential forgetting, k1)             1474 non-null   float64\n",
            " 33  Enriched Normalized Sequence Entropy (exponential forgetting, k1)  1474 non-null   float64\n",
            " 34  Median throughput time                                             1474 non-null   float64\n",
            " 35  Average throughput time                                            1474 non-null   float64\n",
            " 36  PM4Py median throughput time                                       1474 non-null   float64\n",
            " 37  Median cycle time                                                  1474 non-null   float64\n",
            " 38  Average cycle time                                                 1474 non-null   float64\n",
            " 39  Ratio to shortest                                                  356 non-null    float64\n",
            " 40  Ratio to median                                                    1474 non-null   float64\n",
            " 41  Magnitude                                                          1474 non-null   int64  \n",
            " 42  Support                                                            1474 non-null   int64  \n",
            " 43  Variety                                                            1474 non-null   int64  \n",
            " 44  Level of detail                                                    1474 non-null   float64\n",
            " 45  Time granularity                                                   1474 non-null   float64\n",
            " 46  Structure                                                          1474 non-null   float64\n",
            " 47  Affinity                                                           1408 non-null   float64\n",
            " 48  Minimum trace length                                               1474 non-null   int64  \n",
            " 49  Average trace length                                               1474 non-null   float64\n",
            " 50  Maximum trace length                                               1474 non-null   int64  \n",
            " 51  Distinct traces                                                    1474 non-null   float64\n",
            " 52  Deviation from random                                              1474 non-null   float64\n",
            " 53  Lempel-Ziv                                                         1474 non-null   int64  \n",
            " 54  Pentland task complexity                                           1474 non-null   int64  \n",
            " 55  File                                                               1474 non-null   object \n",
            "dtypes: float64(42), int64(11), object(3)\n",
            "memory usage: 645.0+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "column_indices = [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
        "                  21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
        "                  41, 42, 43, 44, 45, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54]\n",
        "\n",
        "# Select the columns\n",
        "datas_filtered = datas.iloc[:, column_indices]"
      ],
      "metadata": {
        "id": "lBpW87DbCVn-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datas_filtered.info()"
      ],
      "metadata": {
        "id": "BEpizd4MlMvl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f1d2d03-076b-4e57-e00e-3e912fd9219e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1474 entries, 0 to 1473\n",
            "Data columns (total 48 columns):\n",
            " #   Column                                                             Non-Null Count  Dtype  \n",
            "---  ------                                                             --------------  -----  \n",
            " 0   Cases                                                              1474 non-null   int64  \n",
            " 1   Number of distinct activities                                      1474 non-null   int64  \n",
            " 2   Number of simple cycles in period                                  1474 non-null   int64  \n",
            " 3   Average number of simple cycles per trace                          1474 non-null   float64\n",
            " 4   Median number of simple cycles per trace                           1474 non-null   float64\n",
            " 5   Number of activity repetitions in period                           1474 non-null   int64  \n",
            " 6   Average number of activity repetitions per trace                   1474 non-null   float64\n",
            " 7   Median number of activity repetitions per trace                    1474 non-null   float64\n",
            " 8   Number of participants in period                                   1429 non-null   float64\n",
            " 9   Average number of participants per trace                           1429 non-null   float64\n",
            " 10  Median number of participants per trace                            1429 non-null   float64\n",
            " 11  Handover of work in period                                         1429 non-null   float64\n",
            " 12  Average handover of work per trace                                 1429 non-null   float64\n",
            " 13  Median handover of work per trace                                  1429 non-null   float64\n",
            " 14  Average handover of work from participant                          1429 non-null   float64\n",
            " 15  Median handover of work from participant                           1429 non-null   float64\n",
            " 16  Simple Variant Entropy                                             1474 non-null   float64\n",
            " 17  Simple Normalized Variant Entropy                                  1474 non-null   float64\n",
            " 18  Simple Sequence Entropy                                            1474 non-null   float64\n",
            " 19  Simple Normalized Sequence Entropy                                 1474 non-null   float64\n",
            " 20  Simple Sequence Entropy (linear forgetting)                        1474 non-null   float64\n",
            " 21  Simple Normalized Sequence Entropy (linear forgetting)             1474 non-null   float64\n",
            " 22  Simple Sequence Entropy (exponential forgetting, k1)               1474 non-null   float64\n",
            " 23  Simple Normalized Sequence Entropy (exponential forgetting, k1)    1474 non-null   float64\n",
            " 24  Enriched Variant Entropy                                           1474 non-null   float64\n",
            " 25  Enriched Normalized Variant Entropy                                1474 non-null   float64\n",
            " 26  Enriched Sequence Entropy                                          1474 non-null   float64\n",
            " 27  Enriched Normalized Sequence Entropy                               1474 non-null   float64\n",
            " 28  Enriched Sequence Entropy (linear forgetting)                      1474 non-null   float64\n",
            " 29  Enriched Normalized Sequence Entropy (linear forgetting)           1474 non-null   float64\n",
            " 30  Enriched Sequence Entropy (exponential forgetting, k1)             1474 non-null   float64\n",
            " 31  Enriched Normalized Sequence Entropy (exponential forgetting, k1)  1474 non-null   float64\n",
            " 32  Median throughput time                                             1474 non-null   float64\n",
            " 33  Magnitude                                                          1474 non-null   int64  \n",
            " 34  Support                                                            1474 non-null   int64  \n",
            " 35  Variety                                                            1474 non-null   int64  \n",
            " 36  Level of detail                                                    1474 non-null   float64\n",
            " 37  Time granularity                                                   1474 non-null   float64\n",
            " 38  Time granularity                                                   1474 non-null   float64\n",
            " 39  Structure                                                          1474 non-null   float64\n",
            " 40  Affinity                                                           1408 non-null   float64\n",
            " 41  Minimum trace length                                               1474 non-null   int64  \n",
            " 42  Average trace length                                               1474 non-null   float64\n",
            " 43  Maximum trace length                                               1474 non-null   int64  \n",
            " 44  Distinct traces                                                    1474 non-null   float64\n",
            " 45  Deviation from random                                              1474 non-null   float64\n",
            " 46  Lempel-Ziv                                                         1474 non-null   int64  \n",
            " 47  Pentland task complexity                                           1474 non-null   int64  \n",
            "dtypes: float64(37), int64(11)\n",
            "memory usage: 552.9 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datas['File'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kf0QqsElBCpH",
        "outputId": "5280bea7-af88-4450-c3ac-a23b6c6ecca7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "File\n",
              "BPI_Challenge_2019_metrics.csv                868\n",
              "BPIC15_4_metrics.csv                           65\n",
              "BPIC15_5_metrics.csv                           65\n",
              "BPIC15_3_metrics.csv                           63\n",
              "2020_PermitLog_metrics.csv                     60\n",
              "BPIC15_1_metrics.csv                           59\n",
              "BPIC15_2_metrics.csv                           58\n",
              "BPI_Challenge_2018_metrics.csv                 45\n",
              "2020_InternationalDeclarations_metrics.csv     44\n",
              "Hospital_log_metrics.csv                       39\n",
              "2020_RequestForPayment_metrics.csv             32\n",
              "2020_DomesticDeclarations_metrics.csv          30\n",
              "2020_PrepaidTravelCost_metrics.csv             26\n",
              "BPI_Challenge_2017_metrics.csv                 14\n",
              "financial_log_metrics.csv                       6\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Check for missing values\n",
        "null_columns = datas_filtered.columns[datas_filtered.isnull().any()].tolist()\n",
        "print(\"Columns with null values:\")\n",
        "print(null_columns)\n",
        "\n",
        "# Check for infinite values\n",
        "#inf_columns = datas_filtered.columns[np.isinf(datas_filtered).any()].tolist()\n",
        "#print(\"Columns with infinite values:\")\n",
        "#print(inf_columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RD1tqRNZLWsz",
        "outputId": "c59cc8e9-a72f-43cf-db8e-029ce3fb3e51"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns with null values:\n",
            "['Number of participants in period', 'Average number of participants per trace', 'Median number of participants per trace', 'Handover of work in period', 'Average handover of work per trace', 'Median handover of work per trace', 'Average handover of work from participant', 'Median handover of work from participant', 'Affinity']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### There are null values in some columns"
      ],
      "metadata": {
        "id": "D8bAWX2WLhee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows where 'Affinity' is null\n",
        "datas_filtered = datas_filtered.dropna(subset=['Affinity', 'Number of participants in period', 'Handover of work in period',\n",
        "                                               'Median handover of work from participant', 'Average handover of work from participant',\n",
        "                                               'Median handover of work per trace', 'Average handover of work per trace', 'Median number of participants per trace',\n",
        "                                               'Average number of participants per trace'])\n",
        "\n",
        "# Now 'df' is your dataframe with rows dropped where 'Affinity' is null"
      ],
      "metadata": {
        "id": "9yVEkt-tL7RT"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FULL** **MODELS**\n"
      ],
      "metadata": {
        "id": "Mx8Q-MSrWpn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the dependent variable (median throughput time)\n",
        "y = datas_filtered[\"Median throughput time\"]\n",
        "\n",
        "# Define the independent variables (all other metrics)\n",
        "X = datas_filtered.drop(\"Median throughput time\", axis=1)\n",
        "\n",
        "# Add a constant to the independent variables matrix\n",
        "X = sm.add_constant(X)\n",
        "y"
      ],
      "metadata": {
        "id": "AOoxw2RXW1iF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb4052f3-d0eb-421e-a2b2-d649d7ac2248"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         572551.5\n",
              "1         638583.0\n",
              "2         606969.0\n",
              "3         694697.0\n",
              "4         786880.0\n",
              "           ...    \n",
              "1424    48098190.0\n",
              "1425    66773640.0\n",
              "1426    66773640.0\n",
              "1427    66773640.0\n",
              "1428    66773640.0\n",
              "Name: Median throughput time, Length: 1363, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "def forward_selection(X, y):\n",
        "    initial_list = []\n",
        "    included = list(initial_list)\n",
        "    while True:\n",
        "        changed=False\n",
        "        excluded = list(set(X.columns)-set(included))\n",
        "        best_aic = float('inf')\n",
        "        for new_column in excluded:\n",
        "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
        "            if model.aic < best_aic:\n",
        "                best_aic = model.aic\n",
        "                best_feature = new_column\n",
        "        if best_aic < float('inf'):\n",
        "            included.append(best_feature)\n",
        "            changed=True\n",
        "        if not changed:\n",
        "            break\n",
        "    print('Final model R-squared: {:.6}'.format(model.rsquared))\n",
        "    return included, model\n",
        "\n",
        "def backward_elimination(X, y):\n",
        "    included=list(X.columns)\n",
        "    while True:\n",
        "        changed=False\n",
        "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
        "        worst_aic = model.aic\n",
        "        worst_feature = None\n",
        "        for column in included:\n",
        "            temp_included = included[:]\n",
        "            temp_included.remove(column)\n",
        "            temp_model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[temp_included]))).fit()\n",
        "            if temp_model.aic < worst_aic:\n",
        "                worst_aic = temp_model.aic\n",
        "                worst_feature = column\n",
        "        if worst_feature is not None:\n",
        "            included.remove(worst_feature)\n",
        "            changed=True\n",
        "        if not changed:\n",
        "            break\n",
        "    print('Final model R-squared: {:.6}'.format(model.rsquared))\n",
        "    return included, model\n",
        "\n",
        "def stepwise_selection(X, y):\n",
        "    included, model = forward_selection(X, y)\n",
        "    included, model = backward_elimination(X[included], y)\n",
        "    final_model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
        "    print('Final model R-squared: {:.6}'.format(final_model.rsquared))\n",
        "    return included, final_model"
      ],
      "metadata": {
        "id": "XTaLghMsWk0j"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_forward, model_fw = forward_selection(X, y)\n",
        "result_backward, model_el = backward_elimination(X, y)\n",
        "result_stepwise, model_sw = stepwise_selection(X, y)\n",
        "\n",
        "print(len(result_forward))\n",
        "print(len(result_backward))\n",
        "print(len(result_stepwise))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3gUF9LZWk7b",
        "outputId": "39d7b66d-a3ef-4763-f200-6ec0495e1a9f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final model R-squared: 0.988188\n",
            "Final model R-squared: 0.988166\n",
            "Final model R-squared: 0.988188\n",
            "Final model R-squared: 0.988185\n",
            "Final model R-squared: 0.988185\n",
            "47\n",
            "44\n",
            "46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SIGNIFICANT MODELS**"
      ],
      "metadata": {
        "id": "gmYKDAvJXDRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "def forward_selection(X, y):\n",
        "    initial_list = []\n",
        "    included = list(initial_list)\n",
        "    while True:\n",
        "        excluded = list(set(X.columns) - set(included))\n",
        "        if len(excluded) == 0:  # Check if 'excluded' is empty\n",
        "            break\n",
        "        best_aic = float('inf')\n",
        "        for new_column in excluded:\n",
        "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included + [new_column]]))).fit()\n",
        "            if model.aic < best_aic:\n",
        "                best_aic = model.aic\n",
        "                best_feature = new_column\n",
        "        included.append(best_feature)\n",
        "    # Filtering step\n",
        "    final_model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
        "    final_cols = final_model.pvalues.loc[final_model.pvalues.index.isin(included)]\n",
        "    included = final_cols[final_cols < 0.001].index.tolist()\n",
        "    print('Final model R-squared: {:.6}'.format(final_model.rsquared))\n",
        "    return included\n",
        "\n",
        "def backward_elimination(X, y):\n",
        "    included = list(X.columns)\n",
        "    while True:\n",
        "        changed = False\n",
        "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
        "        worst_aic = model.aic\n",
        "        worst_feature = None\n",
        "        for column in included:\n",
        "            temp_included = included[:]\n",
        "            temp_included.remove(column)\n",
        "            temp_model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[temp_included]))).fit()\n",
        "            if temp_model.aic < worst_aic:\n",
        "                worst_aic = temp_model.aic\n",
        "                worst_feature = column\n",
        "        if worst_feature is not None:\n",
        "            included.remove(worst_feature)\n",
        "            changed = True\n",
        "        if not changed:\n",
        "            break\n",
        "    # Filtering step\n",
        "    final_model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
        "    final_cols = final_model.pvalues.loc[final_model.pvalues.index.isin(included)]\n",
        "    included = final_cols[final_cols < 0.001].index.tolist()\n",
        "    print('Final model R-squared: {:.6}'.format(final_model.rsquared))\n",
        "    return included\n",
        "\n",
        "def stepwise_selection(X, y):\n",
        "    included = forward_selection(X, y)\n",
        "    included = backward_elimination(X[included], y)\n",
        "    # Filtering step\n",
        "    final_model = sm.OLS(y, sm.add_constant(X[included])).fit()  # Removed unnecessary DataFrame conversion\n",
        "    final_cols = final_model.pvalues.loc[final_model.pvalues.index.isin(included)]\n",
        "    included = final_cols[final_cols < 0.001].index.tolist()\n",
        "    print('Final model R-squared: {:.6}'.format(final_model.rsquared))\n",
        "    return included\n",
        "\n",
        "\n",
        "result_forward = forward_selection(X, y)\n",
        "result_backward = backward_elimination(X, y)\n",
        "result_stepwise = stepwise_selection(X, y)\n",
        "\n",
        "print(len(result_forward))\n",
        "print(len(result_backward))\n",
        "print(len(result_stepwise))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIqzzJ41BaLv",
        "outputId": "af4ebc1b-05ce-4c5a-f173-bdb6352515f4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final model R-squared: 0.988188\n",
            "Final model R-squared: 0.988166\n",
            "Final model R-squared: 0.988188\n",
            "Final model R-squared: 0.985513\n",
            "Final model R-squared: 0.985422\n",
            "23\n",
            "28\n",
            "51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MINIMAL MODELS**\n"
      ],
      "metadata": {
        "id": "DgPcWaERPt5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_variables = {'size':['Magnitude',\n",
        "                          'Variety',\n",
        "                          'Support',\n",
        "                          'Time granularity',\n",
        "                          'Minimum trace length',\n",
        "                          'Average trace length',\n",
        "                          'Maximum trace length'],\n",
        "\n",
        "                  'variation':['Level of detail',\n",
        "                               'Pentland task complexity ',\n",
        "                               'Lempel-Ziv',\n",
        "                               'Distinct traces',\n",
        "                               'Structure'],\n",
        "\n",
        "                  'distance':['Affinity',\n",
        "                              'Deviation from random'],\n",
        "\n",
        "                  'entropy':['Simple Variant Entropy',\n",
        "                             'Simple Sequence Entropy',\n",
        "                             'Simple Normalized Variant Entropy',\n",
        "                             'Simple Normalized Sequence Entropy',\n",
        "                             'Enriched Sequence Entropy',\n",
        "                             'Enriched Variant Entropy',\n",
        "                             'Enriched Normalized Sequence Entropy',\n",
        "                             'Enriched Normalized Variant Entropy'],\n",
        "\n",
        "                  'generic':['Cases',\n",
        "                             'Number of activity repetitions in period ',\n",
        "                             'Average number of simple cycles per trace',\n",
        "                             'Median number of simple cycles per trace',\n",
        "                             'Number of distinct activities',\n",
        "                             'Number of simple cycles in period',\n",
        "                             'Average number of activity repetitions per trace',\n",
        "                             'Median number of activity repetitions per trace',\n",
        "                             'Number of participants in period',\n",
        "                             'Average number of participants per trace',\n",
        "                             'Median number of participants per trace',\n",
        "                             'Handover of work in period',\n",
        "                             'Average handover of work per trace',\n",
        "                             'Median handover of work per trace',\n",
        "                             'Average handover of work from participant',\n",
        "                             'Median handover of work from participant']}"
      ],
      "metadata": {
        "id": "mbgNkqoDTjer"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "\n",
        "def select_best_variable_per_category(X, y, categories):\n",
        "    best_variables = {}\n",
        "    for category, variables in categories.items():\n",
        "        best_pval = float('inf')\n",
        "        best_r2 = float('-inf')\n",
        "        best_variable = None\n",
        "        for variable in variables:\n",
        "            if variable in X.columns:\n",
        "                model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[variable]))).fit()\n",
        "                if model.pvalues[1] < best_pval or (model.pvalues[1] == best_pval and model.rsquared > best_r2):\n",
        "                    best_pval = model.pvalues[1]\n",
        "                    best_r2 = model.rsquared\n",
        "                    best_variable = variable\n",
        "        best_variables[category] = best_variable\n",
        "    return best_variables\n",
        "\n",
        "def forward_selection(X, y, best_variables):\n",
        "    initial_list = list(best_variables.values())\n",
        "    included = list(initial_list)\n",
        "    while True:\n",
        "        changed=False\n",
        "        excluded = list(set(X.columns)-set(included))\n",
        "        best_aic = float('inf')\n",
        "        for new_column in excluded:\n",
        "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
        "            if model.aic < best_aic:\n",
        "                best_aic = model.aic\n",
        "                best_feature = new_column\n",
        "        if best_aic < float('inf'):\n",
        "            included.append(best_feature)\n",
        "            changed=True\n",
        "        if not changed:\n",
        "            break\n",
        "    print('Final model R-squared: {:.6}'.format(model.rsquared))\n",
        "    return included\n",
        "\n",
        "def backward_elimination(X, y, best_variables):\n",
        "    initial_list = list(best_variables.values())\n",
        "    included = list(initial_list)\n",
        "    while True:\n",
        "        changed=False\n",
        "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
        "        worst_aic = model.aic\n",
        "        worst_feature = None\n",
        "        for column in included:\n",
        "            temp_included = included[:]\n",
        "            temp_included.remove(column)\n",
        "            temp_model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[temp_included]))).fit()\n",
        "            if temp_model.aic < worst_aic:\n",
        "                worst_aic = temp_model.aic\n",
        "                worst_feature = column\n",
        "        if worst_feature is not None:\n",
        "            included.remove(worst_feature)\n",
        "            changed=True\n",
        "        if not changed:\n",
        "            break\n",
        "    print('Final model R-squared: {:.6}'.format(model.rsquared))\n",
        "    return included\n",
        "\n",
        "def stepwise_selection(X, y, best_variables):\n",
        "    included = forward_selection(X, y, best_variables)\n",
        "    included = backward_elimination(X[included], y, best_variables)\n",
        "    final_model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
        "    print('Final model R-squared: {:.6}'.format(final_model.rsquared))\n",
        "    return included\n",
        "\n",
        "# Call the function to select the best variable per category\n",
        "best_variables = select_best_variable_per_category(X, y, best_variables)\n",
        "\n",
        "# Call the forward, backward, and stepwise selection functions\n",
        "result_forward = forward_selection(X, y, best_variables)\n",
        "result_backward = backward_elimination(X, y, best_variables)\n",
        "result_stepwise = stepwise_selection(X, y, best_variables)\n",
        "\n",
        "print('Best variable for each category:')\n",
        "print(best_variables)\n",
        "print('Resulting features (forward):')\n",
        "print(result_forward)\n",
        "print('Resulting features (backward):')\n",
        "print(result_backward)\n",
        "print('Resulting features (stepwise):')\n",
        "print(result_stepwise)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9Ee2EDeR8Om",
        "outputId": "5c3a3e88-db60-4e2c-c95f-b7700103465f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final model R-squared: 0.988188\n",
            "Final model R-squared: 0.931999\n",
            "Final model R-squared: 0.988188\n",
            "Final model R-squared: 0.931999\n",
            "Final model R-squared: 0.931999\n",
            "Best variable for each category:\n",
            "{'size': 'Average trace length', 'variation': 'Distinct traces', 'distance': 'Affinity', 'entropy': 'Simple Normalized Sequence Entropy', 'generic': 'Median number of participants per trace'}\n",
            "Resulting features (forward):\n",
            "['Average trace length', 'Distinct traces', 'Affinity', 'Simple Normalized Sequence Entropy', 'Median number of participants per trace', 'Deviation from random', 'Median number of simple cycles per trace', 'Average handover of work from participant', 'Minimum trace length', 'Enriched Normalized Sequence Entropy', 'Average number of simple cycles per trace', 'Simple Normalized Variant Entropy', 'Median number of activity repetitions per trace', 'Average number of participants per trace', 'Enriched Normalized Sequence Entropy (exponential forgetting, k1)', 'Simple Normalized Sequence Entropy (linear forgetting)', 'Simple Normalized Sequence Entropy (exponential forgetting, k1)', 'Enriched Normalized Sequence Entropy (linear forgetting)', 'Level of detail', 'Average handover of work per trace', 'Lempel-Ziv', 'Simple Sequence Entropy (exponential forgetting, k1)', 'Median handover of work from participant', 'Median handover of work per trace', 'Structure', 'Time granularity', 'Number of distinct activities', 'Simple Sequence Entropy (linear forgetting)', 'Pentland task complexity', 'Enriched Sequence Entropy (linear forgetting)', 'Cases', 'Variety', 'Enriched Normalized Variant Entropy', 'Average number of activity repetitions per trace', 'Support', 'Enriched Sequence Entropy (exponential forgetting, k1)', 'Simple Variant Entropy', 'Handover of work in period', 'Magnitude', 'Enriched Variant Entropy', 'Number of simple cycles in period', 'const', 'Enriched Sequence Entropy', 'Number of participants in period', 'Simple Sequence Entropy', 'Maximum trace length', 'Number of activity repetitions in period']\n",
            "Resulting features (backward):\n",
            "['Average trace length', 'Distinct traces', 'Affinity', 'Simple Normalized Sequence Entropy', 'Median number of participants per trace']\n",
            "Resulting features (stepwise):\n",
            "['Average trace length', 'Distinct traces', 'Affinity', 'Simple Normalized Sequence Entropy', 'Median number of participants per trace']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ADDING** **THE** **DUMMMY** **VARIABLE**"
      ],
      "metadata": {
        "id": "7YrO0ZIid7dH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def assign_value(y):\n",
        "    if y == ('BPIC15_3_metrics.csv'or 'BPIC15_4_metrics.csv' or 'BPIC15_5_metrics.csv' or 'BPIC15_2_metrics.csv' or 'BPIC15_1_metrics.csv' or 'BPI_Challenge_2018_metrics.csv'):  # replace this condition with your own\n",
        "        return 'Public Administration'\n",
        "    if y == ('2020_PrepaidTravelCost_metrics.csv' or '2020_DomesticDeclarations_metrics.csv' or '2020_RequestForPayment_metrics.csv' or '2020_InternationalDeclarations_metrics.csv' or '2020_PermitLog_metrics.csv'):\n",
        "        return 'Education'\n",
        "    if y == 'Hospital_log_metrics.csv':\n",
        "      return 'Healthcare'\n",
        "    if y == 'BPI_Challenge_2017_metrics.csv':\n",
        "      return 'Finance'\n",
        "    if y == 'BPI_Challenge_2019_metrics.csv':\n",
        "      return 'Manufacturing'\n",
        "\n",
        "dummy_filtered = datas.copy()\n",
        "\n",
        "# Apply the function to the 'y' column and assign the result to a new column 'x'\n",
        "dummy_filtered['INDUSTRY_DUMMY_VARIABLE'] = datas['File'].apply(assign_value)"
      ],
      "metadata": {
        "id": "O5dJ6Yi1Kj5K"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_filtered['INDUSTRY_DUMMY_VARIABLE'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZsU5XwyNk5e",
        "outputId": "bf3b828f-fcd3-4e1c-be29-6f5252508a69"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "INDUSTRY_DUMMY_VARIABLE\n",
              "Manufacturing            868\n",
              "Public Administration     63\n",
              "Healthcare                39\n",
              "Education                 26\n",
              "Finance                   14\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_filtered.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5v7E6YhPaQa",
        "outputId": "6e675d50-3bcc-45be-b3a5-858527bb8e17"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1474 entries, 0 to 1473\n",
            "Data columns (total 57 columns):\n",
            " #   Column                                                             Non-Null Count  Dtype  \n",
            "---  ------                                                             --------------  -----  \n",
            " 0   Date                                                               1474 non-null   object \n",
            " 1   Cases                                                              1474 non-null   int64  \n",
            " 2   Distinct activities                                                1474 non-null   object \n",
            " 3   Number of distinct activities                                      1474 non-null   int64  \n",
            " 4   Number of simple cycles in period                                  1474 non-null   int64  \n",
            " 5   Average number of simple cycles per trace                          1474 non-null   float64\n",
            " 6   Median number of simple cycles per trace                           1474 non-null   float64\n",
            " 7   Number of activity repetitions in period                           1474 non-null   int64  \n",
            " 8   Average number of activity repetitions per trace                   1474 non-null   float64\n",
            " 9   Median number of activity repetitions per trace                    1474 non-null   float64\n",
            " 10  Number of participants in period                                   1429 non-null   float64\n",
            " 11  Average number of participants per trace                           1429 non-null   float64\n",
            " 12  Median number of participants per trace                            1429 non-null   float64\n",
            " 13  Handover of work in period                                         1429 non-null   float64\n",
            " 14  Average handover of work per trace                                 1429 non-null   float64\n",
            " 15  Median handover of work per trace                                  1429 non-null   float64\n",
            " 16  Average handover of work from participant                          1429 non-null   float64\n",
            " 17  Median handover of work from participant                           1429 non-null   float64\n",
            " 18  Simple Variant Entropy                                             1474 non-null   float64\n",
            " 19  Simple Normalized Variant Entropy                                  1474 non-null   float64\n",
            " 20  Simple Sequence Entropy                                            1474 non-null   float64\n",
            " 21  Simple Normalized Sequence Entropy                                 1474 non-null   float64\n",
            " 22  Simple Sequence Entropy (linear forgetting)                        1474 non-null   float64\n",
            " 23  Simple Normalized Sequence Entropy (linear forgetting)             1474 non-null   float64\n",
            " 24  Simple Sequence Entropy (exponential forgetting, k1)               1474 non-null   float64\n",
            " 25  Simple Normalized Sequence Entropy (exponential forgetting, k1)    1474 non-null   float64\n",
            " 26  Enriched Variant Entropy                                           1474 non-null   float64\n",
            " 27  Enriched Normalized Variant Entropy                                1474 non-null   float64\n",
            " 28  Enriched Sequence Entropy                                          1474 non-null   float64\n",
            " 29  Enriched Normalized Sequence Entropy                               1474 non-null   float64\n",
            " 30  Enriched Sequence Entropy (linear forgetting)                      1474 non-null   float64\n",
            " 31  Enriched Normalized Sequence Entropy (linear forgetting)           1474 non-null   float64\n",
            " 32  Enriched Sequence Entropy (exponential forgetting, k1)             1474 non-null   float64\n",
            " 33  Enriched Normalized Sequence Entropy (exponential forgetting, k1)  1474 non-null   float64\n",
            " 34  Median throughput time                                             1474 non-null   float64\n",
            " 35  Average throughput time                                            1474 non-null   float64\n",
            " 36  PM4Py median throughput time                                       1474 non-null   float64\n",
            " 37  Median cycle time                                                  1474 non-null   float64\n",
            " 38  Average cycle time                                                 1474 non-null   float64\n",
            " 39  Ratio to shortest                                                  356 non-null    float64\n",
            " 40  Ratio to median                                                    1474 non-null   float64\n",
            " 41  Magnitude                                                          1474 non-null   int64  \n",
            " 42  Support                                                            1474 non-null   int64  \n",
            " 43  Variety                                                            1474 non-null   int64  \n",
            " 44  Level of detail                                                    1474 non-null   float64\n",
            " 45  Time granularity                                                   1474 non-null   float64\n",
            " 46  Structure                                                          1474 non-null   float64\n",
            " 47  Affinity                                                           1408 non-null   float64\n",
            " 48  Minimum trace length                                               1474 non-null   int64  \n",
            " 49  Average trace length                                               1474 non-null   float64\n",
            " 50  Maximum trace length                                               1474 non-null   int64  \n",
            " 51  Distinct traces                                                    1474 non-null   float64\n",
            " 52  Deviation from random                                              1474 non-null   float64\n",
            " 53  Lempel-Ziv                                                         1474 non-null   int64  \n",
            " 54  Pentland task complexity                                           1474 non-null   int64  \n",
            " 55  File                                                               1474 non-null   object \n",
            " 56  INDUSTRY_DUMMY_VARIABLE                                            1010 non-null   object \n",
            "dtypes: float64(42), int64(11), object(4)\n",
            "memory usage: 656.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "column_indices = [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
        "                  21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
        "                  41, 42, 43, 44, 45, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56]\n",
        "\n",
        "# Select the columns\n",
        "dummy_filtered = dummy_filtered.iloc[:, column_indices]\n",
        "\n",
        "dummy_filtered = dummy_filtered.dropna(subset=['Affinity', 'Number of participants in period', 'Handover of work in period',\n",
        "                                               'Median handover of work from participant', 'Average handover of work from participant',\n",
        "                                               'Median handover of work per trace', 'Average handover of work per trace', 'Median number of participants per trace',\n",
        "                                               'Average number of participants per trace'])\n"
      ],
      "metadata": {
        "id": "usFhAxacNr63"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "enc = LabelEncoder()\n",
        "\n",
        "dummy_filtered['INDUSTRY_DUMMY_VARIABLE'] = enc.fit_transform(dummy_filtered['INDUSTRY_DUMMY_VARIABLE'])"
      ],
      "metadata": {
        "id": "EBssavodQHxS"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = dummy_filtered[\"Median throughput time\"]\n",
        "\n",
        "# Define the independent variables (all other metrics)\n",
        "X = dummy_filtered.drop(\"Median throughput time\", axis=1)\n",
        "\n",
        "# Add a constant to the independent variables matrix\n",
        "X = sm.add_constant(X)"
      ],
      "metadata": {
        "id": "H0MMrM6dTseq"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FULL MODELS WITH DUMMY VARIABLE**"
      ],
      "metadata": {
        "id": "KtojWWFuW3gH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_selection(X, y):\n",
        "    initial_list = []\n",
        "    included = list(initial_list)\n",
        "    while True:\n",
        "        changed=False\n",
        "        excluded = list(set(X.columns)-set(included))\n",
        "        best_aic = float('inf')\n",
        "        for new_column in excluded:\n",
        "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
        "            if model.aic < best_aic:\n",
        "                best_aic = model.aic\n",
        "                best_feature = new_column\n",
        "        if best_aic < float('inf'):\n",
        "            included.append(best_feature)\n",
        "            changed=True\n",
        "        if not changed:\n",
        "            break\n",
        "    print('Final model R-squared: {:.6}'.format(model.rsquared))\n",
        "    return included\n",
        "\n",
        "def backward_elimination(X, y):\n",
        "    included=list(X.columns)\n",
        "    while True:\n",
        "        changed=False\n",
        "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
        "        worst_aic = model.aic\n",
        "        worst_feature = None\n",
        "        for column in included:\n",
        "            temp_included = included[:]\n",
        "            temp_included.remove(column)\n",
        "            temp_model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[temp_included]))).fit()\n",
        "            if temp_model.aic < worst_aic:\n",
        "                worst_aic = temp_model.aic\n",
        "                worst_feature = column\n",
        "        if worst_feature is not None:\n",
        "            included.remove(worst_feature)\n",
        "            changed=True\n",
        "        if not changed:\n",
        "            break\n",
        "    print('Final model R-squared: {:.6}'.format(model.rsquared))\n",
        "    return included\n",
        "\n",
        "def stepwise_selection(X, y):\n",
        "    included = forward_selection(X, y)\n",
        "    included = backward_elimination(X[included], y)\n",
        "    final_model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
        "    print('Final model R-squared: {:.6}'.format(final_model.rsquared))\n",
        "    return included"
      ],
      "metadata": {
        "id": "qLlYi3ZQbLPY"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_forward = forward_selection(X, y)\n",
        "result_backward = backward_elimination(X, y)\n",
        "result_stepwise = stepwise_selection(X, y)\n",
        "\n",
        "print(len(result_forward))\n",
        "print('resulting features (forward):')\n",
        "print(result_forward)\n",
        "print(len(result_backward))\n",
        "print('resulting features (backward):')\n",
        "print(result_backward)\n",
        "print(len(result_stepwise))\n",
        "print('resulting features (stepwise):')\n",
        "print(result_stepwise)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQuTj5XPPnnQ",
        "outputId": "a15b8b50-3cf4-4191-bb14-9ee3aba44db6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final model R-squared: 0.9884\n",
            "Final model R-squared: 0.988392\n",
            "Final model R-squared: 0.9884\n",
            "Final model R-squared: 0.988359\n",
            "Final model R-squared: 0.988359\n",
            "48\n",
            "resulting features (forward):\n",
            "['Affinity', 'Simple Normalized Variant Entropy', 'Deviation from random', 'Enriched Normalized Sequence Entropy', 'Average handover of work per trace', 'Average number of participants per trace', 'Median number of participants per trace', 'Level of detail', 'Lempel-Ziv', 'Number of simple cycles in period', 'Maximum trace length', 'Number of activity repetitions in period', 'Median number of simple cycles per trace', 'Median number of activity repetitions per trace', 'Simple Sequence Entropy', 'Structure', 'Pentland task complexity', 'INDUSTRY_DUMMY_VARIABLE', 'Number of distinct activities', 'Enriched Normalized Sequence Entropy (linear forgetting)', 'Simple Normalized Sequence Entropy (linear forgetting)', 'Time granularity', 'Simple Normalized Sequence Entropy (exponential forgetting, k1)', 'Distinct traces', 'Median handover of work from participant', 'Cases', 'Simple Variant Entropy', 'Median handover of work per trace', 'Average trace length', 'Average number of simple cycles per trace', 'Enriched Sequence Entropy (linear forgetting)', 'Enriched Normalized Variant Entropy', 'Support', 'Average number of activity repetitions per trace', 'const', 'Variety', 'Handover of work in period', 'Enriched Normalized Sequence Entropy (exponential forgetting, k1)', 'Simple Normalized Sequence Entropy', 'Magnitude', 'Simple Sequence Entropy (linear forgetting)', 'Average handover of work from participant', 'Enriched Variant Entropy', 'Enriched Sequence Entropy', 'Enriched Sequence Entropy (exponential forgetting, k1)', 'Simple Sequence Entropy (exponential forgetting, k1)', 'Number of participants in period', 'Minimum trace length']\n",
            "44\n",
            "resulting features (backward):\n",
            "['const', 'Cases', 'Number of distinct activities', 'Number of simple cycles in period', 'Average number of simple cycles per trace', 'Median number of simple cycles per trace', 'Average number of activity repetitions per trace', 'Median number of activity repetitions per trace', 'Number of participants in period', 'Average number of participants per trace', 'Median number of participants per trace', 'Handover of work in period', 'Average handover of work per trace', 'Median handover of work per trace', 'Median handover of work from participant', 'Simple Variant Entropy', 'Simple Normalized Variant Entropy', 'Simple Sequence Entropy', 'Simple Normalized Sequence Entropy', 'Simple Sequence Entropy (linear forgetting)', 'Simple Normalized Sequence Entropy (linear forgetting)', 'Simple Sequence Entropy (exponential forgetting, k1)', 'Simple Normalized Sequence Entropy (exponential forgetting, k1)', 'Enriched Variant Entropy', 'Enriched Normalized Variant Entropy', 'Enriched Sequence Entropy', 'Enriched Normalized Sequence Entropy', 'Enriched Sequence Entropy (linear forgetting)', 'Enriched Normalized Sequence Entropy (linear forgetting)', 'Enriched Sequence Entropy (exponential forgetting, k1)', 'Enriched Normalized Sequence Entropy (exponential forgetting, k1)', 'Magnitude', 'Support', 'Variety', 'Time granularity', 'Time granularity', 'Structure', 'Affinity', 'Average trace length', 'Distinct traces', 'Deviation from random', 'Lempel-Ziv', 'Pentland task complexity', 'INDUSTRY_DUMMY_VARIABLE']\n",
            "42\n",
            "resulting features (stepwise):\n",
            "['Affinity', 'Simple Normalized Variant Entropy', 'Deviation from random', 'Enriched Normalized Sequence Entropy', 'Average handover of work per trace', 'Average number of participants per trace', 'Median number of participants per trace', 'Level of detail', 'Lempel-Ziv', 'Median number of simple cycles per trace', 'Median number of activity repetitions per trace', 'Structure', 'Pentland task complexity', 'INDUSTRY_DUMMY_VARIABLE', 'Number of distinct activities', 'Enriched Normalized Sequence Entropy (linear forgetting)', 'Simple Normalized Sequence Entropy (linear forgetting)', 'Time granularity', 'Time granularity', 'Simple Normalized Sequence Entropy (exponential forgetting, k1)', 'Distinct traces', 'Median handover of work from participant', 'Cases', 'Simple Variant Entropy', 'Median handover of work per trace', 'Average trace length', 'Average number of simple cycles per trace', 'Enriched Sequence Entropy (linear forgetting)', 'Enriched Normalized Variant Entropy', 'Support', 'Average number of activity repetitions per trace', 'const', 'Variety', 'Enriched Normalized Sequence Entropy (exponential forgetting, k1)', 'Simple Normalized Sequence Entropy', 'Magnitude', 'Simple Sequence Entropy (linear forgetting)', 'Enriched Variant Entropy', 'Enriched Sequence Entropy', 'Enriched Sequence Entropy (exponential forgetting, k1)', 'Simple Sequence Entropy (exponential forgetting, k1)', 'Number of participants in period']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SIGNIFICANT MODELS WITH DUMMY**"
      ],
      "metadata": {
        "id": "S2Ea3efTbZd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_selection(X, y):\n",
        "    initial_list = []\n",
        "    included = list(initial_list)\n",
        "    while True:\n",
        "        changed = False\n",
        "        excluded = list(set(X.columns) - set(included))\n",
        "        best_aic = float('inf')\n",
        "        for new_column in excluded:\n",
        "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included + [new_column]]))).fit()\n",
        "            if model.aic < best_aic:\n",
        "                best_aic = model.aic\n",
        "                best_feature = new_column\n",
        "        if best_aic < float('inf'):\n",
        "            included.append(best_feature)\n",
        "            changed = True\n",
        "        if not changed:\n",
        "            break\n",
        "    # Filtering step\n",
        "    final_model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
        "    final_cols = final_model.pvalues.loc[final_model.pvalues.index.isin(included)]\n",
        "    included = final_cols[final_cols < 0.001].index.tolist()\n",
        "    print('Final model R-squared: {:.6}'.format(final_model.rsquared))\n",
        "    return included\n",
        "\n",
        "def backward_elimination(X, y):\n",
        "    included = list(X.columns)\n",
        "    while True:\n",
        "        changed = False\n",
        "        model = sm.OLS(y, sm.add_constant(X[included])).fit()  # Removed unnecessary DataFrame conversion\n",
        "        worst_aic = model.aic\n",
        "        worst_feature = None\n",
        "        for column in included:\n",
        "            temp_included = included[:]\n",
        "            temp_included.remove(column)\n",
        "            temp_model = sm.OLS(y, sm.add_constant(X[temp_included])).fit()  # Removed unnecessary DataFrame conversion\n",
        "            if temp_model.aic < worst_aic:\n",
        "                worst_aic = temp_model.aic\n",
        "                worst_feature = column\n",
        "        if worst_feature is not None:\n",
        "            included.remove(worst_feature)\n",
        "            changed = True\n",
        "        if not changed:\n",
        "            break\n",
        "    # Filtering step\n",
        "    final_model = sm.OLS(y, sm.add_constant(X[included])).fit()\n",
        "    final_cols = final_model.pvalues.loc[final_model.pvalues.index.isin(included)]\n",
        "    included = final_cols[final_cols < 0.001].index.tolist()\n",
        "    print('Final model R-squared: {:.6}'.format(final_model.rsquared))\n",
        "    return included\n",
        "\n",
        "def stepwise_selection(X, y):\n",
        "    included = forward_selection(X, y)\n",
        "    included = backward_elimination(X[included], y)\n",
        "    # Filtering step\n",
        "    final_model = sm.OLS(y, sm.add_constant(X[included])).fit()  # Removed unnecessary DataFrame conversion\n",
        "    final_cols = final_model.pvalues.loc[final_model.pvalues.index.isin(included)]\n",
        "    included = final_cols[final_cols < 0.001].index.tolist()\n",
        "    print('Final model R-squared: {:.6}'.format(final_model.rsquared))\n",
        "    return included\n",
        "\n",
        "result_forward = forward_selection(X, y)\n",
        "result_backward = backward_elimination(X, y)\n",
        "result_stepwise = stepwise_selection(X, y)\n",
        "\n",
        "print(len(result_forward))\n",
        "print(len(result_backward))\n",
        "print(len(result_stepwise))"
      ],
      "metadata": {
        "id": "Fe5lIIoYP3jl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26b905cf-bc27-4808-b033-22581362ea6c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final model R-squared: 0.9884\n",
            "Final model R-squared: 0.988392\n",
            "Final model R-squared: 0.9884\n",
            "Final model R-squared: 0.976669\n",
            "Final model R-squared: 0.974088\n",
            "19\n",
            "26\n",
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MINIMAL MODELS WITH DUMMY**"
      ],
      "metadata": {
        "id": "0aI2UteAXNul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_variables = {'size':['Magnitude',\n",
        "                          'Variety',\n",
        "                          'Support',\n",
        "                          'Time granularity',\n",
        "                          'Minimum trace length',\n",
        "                          'Average trace length',\n",
        "                          'Maximum trace length'],\n",
        "\n",
        "                  'variation':['Level of detail',\n",
        "                               'Pentland task complexity ',\n",
        "                               'Lempel-Ziv',\n",
        "                               'Distinct traces',\n",
        "                               'Structure'],\n",
        "\n",
        "                  'distance':['Affinity',\n",
        "                              'Deviation from random'],\n",
        "\n",
        "                  'entropy':['Simple Variant Entropy',\n",
        "                             'Simple Sequence Entropy',\n",
        "                             'Simple Normalized Variant Entropy',\n",
        "                             'Simple Normalized Sequence Entropy',\n",
        "                             'Enriched Sequence Entropy',\n",
        "                             'Enriched Variant Entropy',\n",
        "                             'Enriched Normalized Sequence Entropy',\n",
        "                             'Enriched Normalized Variant Entropy'],\n",
        "\n",
        "                  'generic':['Cases',\n",
        "                             'Number of activity repetitions in period ',\n",
        "                             'Average number of simple cycles per trace',\n",
        "                             'Median number of simple cycles per trace',\n",
        "                             'Number of distinct activities',\n",
        "                             'Number of simple cycles in period',\n",
        "                             'Average number of activity repetitions per trace',\n",
        "                             'Median number of activity repetitions per trace',\n",
        "                             'Number of participants in period',\n",
        "                             'Average number of participants per trace',\n",
        "                             'Median number of participants per trace',\n",
        "                             'Handover of work in period',\n",
        "                             'Average handover of work per trace',\n",
        "                             'Median handover of work per trace',\n",
        "                             'Average handover of work from participant',\n",
        "                             'Median handover of work from participant']}"
      ],
      "metadata": {
        "id": "qkTdS4JZcpW9"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "def select_best_variable_per_category(X, y, categories):\n",
        "    best_variables = {}\n",
        "    for category, variables in categories.items():\n",
        "        best_pval = float('inf')\n",
        "        best_r2 = float('-inf')\n",
        "        best_variable = None\n",
        "        for variable in variables:\n",
        "            if variable in X.columns:\n",
        "                model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[variable]))).fit()\n",
        "                if model.pvalues[1] < best_pval or (model.pvalues[1] == best_pval and model.rsquared > best_r2):\n",
        "                    best_pval = model.pvalues[1]\n",
        "                    best_r2 = model.rsquared\n",
        "                    best_variable = variable\n",
        "        best_variables[category] = best_variable\n",
        "    return best_variables\n",
        "\n",
        "def forward_selection(X, y, best_variables):\n",
        "    initial_list = list(best_variables.values())\n",
        "    included = list(initial_list)\n",
        "    while True:\n",
        "        changed=False\n",
        "        excluded = list(set(X.columns)-set(included))\n",
        "        best_aic = float('inf')\n",
        "        for new_column in excluded:\n",
        "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
        "            if model.aic < best_aic:\n",
        "                best_aic = model.aic\n",
        "                best_feature = new_column\n",
        "        if best_aic < float('inf'):\n",
        "            included.append(best_feature)\n",
        "            changed=True\n",
        "        if not changed:\n",
        "            break\n",
        "    print('Final model R-squared: {:.6}'.format(model.rsquared))\n",
        "    return included\n",
        "\n",
        "def backward_elimination(X, y, best_variables):\n",
        "    initial_list = list(best_variables.values())\n",
        "    included = list(initial_list)\n",
        "    while True:\n",
        "        changed=False\n",
        "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
        "        worst_aic = model.aic\n",
        "        worst_feature = None\n",
        "        for column in included:\n",
        "            temp_included = included[:]\n",
        "            temp_included.remove(column)\n",
        "            temp_model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[temp_included]))).fit()\n",
        "            if temp_model.aic < worst_aic:\n",
        "                worst_aic = temp_model.aic\n",
        "                worst_feature = column\n",
        "        if worst_feature is not None:\n",
        "            included.remove(worst_feature)\n",
        "            changed=True\n",
        "        if not changed:\n",
        "            break\n",
        "    print('Final model R-squared: {:.6}'.format(model.rsquared))\n",
        "    return included\n",
        "\n",
        "def stepwise_selection(X, y, best_variables):\n",
        "    included = forward_selection(X, y, best_variables)\n",
        "    included = backward_elimination(X[included], y, best_variables)\n",
        "    final_model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
        "    print('Final model R-squared: {:.6}'.format(final_model.rsquared))\n",
        "    return included\n",
        "\n",
        "# Call the function to select the best variable per category\n",
        "best_variables = select_best_variable_per_category(X, y, best_variables)\n",
        "\n",
        "# Call the forward, backward, and stepwise selection functions\n",
        "result_forward = forward_selection(X, y, best_variables)\n",
        "result_backward = backward_elimination(X, y, best_variables)\n",
        "result_stepwise = stepwise_selection(X, y, best_variables)\n",
        "\n",
        "print('Best variable for each category:')\n",
        "print(best_variables)\n",
        "print('Resulting features (forward):')\n",
        "print(result_forward)\n",
        "print('Resulting features (backward):')\n",
        "print(result_backward)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWUr8nRubhoR",
        "outputId": "150cdf9a-9b81-468c-e693-35300464df9a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final model R-squared: 0.9884\n",
            "Final model R-squared: 0.931999\n",
            "Final model R-squared: 0.9884\n",
            "Final model R-squared: 0.931999\n",
            "Final model R-squared: 0.931999\n",
            "Best variable for each category:\n",
            "{'size': 'Average trace length', 'variation': 'Distinct traces', 'distance': 'Affinity', 'entropy': 'Simple Normalized Sequence Entropy', 'generic': 'Median number of participants per trace'}\n",
            "Resulting features (forward):\n",
            "['Average trace length', 'Distinct traces', 'Affinity', 'Simple Normalized Sequence Entropy', 'Median number of participants per trace', 'Deviation from random', 'Median number of simple cycles per trace', 'Average handover of work from participant', 'Minimum trace length', 'Enriched Normalized Sequence Entropy', 'Average number of simple cycles per trace', 'Simple Normalized Variant Entropy', 'Median number of activity repetitions per trace', 'Average number of participants per trace', 'INDUSTRY_DUMMY_VARIABLE', 'Enriched Normalized Sequence Entropy (exponential forgetting, k1)', 'Simple Normalized Sequence Entropy (linear forgetting)', 'Number of distinct activities', 'Median handover of work per trace', 'Simple Normalized Sequence Entropy (exponential forgetting, k1)', 'Enriched Normalized Sequence Entropy (linear forgetting)', 'Level of detail', 'Average handover of work per trace', 'Lempel-Ziv', 'Simple Sequence Entropy (exponential forgetting, k1)', 'Median handover of work from participant', 'Time granularity', 'Simple Sequence Entropy (linear forgetting)', 'Pentland task complexity', 'Enriched Sequence Entropy (linear forgetting)', 'Structure', 'Enriched Variant Entropy', 'Variety', 'Enriched Normalized Variant Entropy', 'const', 'Average number of activity repetitions per trace', 'Simple Variant Entropy', 'Enriched Sequence Entropy (exponential forgetting, k1)', 'Magnitude', 'Enriched Sequence Entropy', 'Handover of work in period', 'Number of activity repetitions in period', 'Number of simple cycles in period', 'Number of participants in period', 'Support', 'Cases', 'Simple Sequence Entropy', 'Maximum trace length']\n",
            "Resulting features (backward):\n",
            "['Average trace length', 'Distinct traces', 'Affinity', 'Simple Normalized Sequence Entropy', 'Median number of participants per trace']\n"
          ]
        }
      ]
    }
  ]
}